{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification de la paraphrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problématique \n",
    "Il s'agit de dire si deux phrases partagent le même sens, ou autrement dit si elles sont paraphrases l'une de l'autre.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Installation de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luciegabagnou/Documents/MOSEF/ML_AVANCE/PROJET/paraphrase-identification/notebooks\n",
      "Requirement already satisfied: datasets in /Users/luciegabagnou/miniconda/envs/dl_gpu/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: pandas in /Users/luciegabagnou/miniconda/envs/dl_gpu/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: numpy in /Users/luciegabagnou/miniconda/envs/dl_gpu/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.24.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/luciegabagnou/miniconda/envs/dl_gpu/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: nltk in /Users/luciegabagnou/miniconda/envs/dl_gpu/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (3.8.1)\n",
      "Requirement already satisfied: matplotlib in /Users/luciegabagnou/miniconda/envs/dl_gpu/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
      "Requirement already satisfied: gensim in /Users/luciegabagnou/miniconda/envs/dl_gpu/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (4.3.1)\n",
      "Requirement already satisfied: seaborn in /Users/luciegabagnou/miniconda/envs/dl_gpu/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (0.12.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Installation de l'env\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "# Installation des packages nécessaires à ce projet\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luciegabagnou/miniconda/envs/dl_gpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_utils import HuggingFaceExtracting,ETLPipeline,WordEmbedding\n",
    "from scripts.model import SiameseNet,BertTransferModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importation des données\n",
    "\n",
    "Ici, pour collecter les données des données nous avons créée une classe **HuggingFaceExtracting** : une classe pour extraire des données à partir de datasets Hugging Face. Elle comprend des méthodes pour extraire les features et les labels, charger des données de datasets Hugging Face, et exporter des données dans un fichier CSV (ou laisser en DataFrame pandas).\n",
    "Pour rendre uniforme les inputs dans la pipeline de preprocessing, nous avons crée une colonne \"inputs\" composée des paires de phrases sous forme de liste, et une \"labels\" ayant les labels bien encodés.\n",
    "\n",
    "\n",
    "A l'origine:\n",
    "On a effectué une analyse sur l'ensemble du jeu de données visible sur [HuggingFace](https://huggingface.co/datasets/bigscience/P3/viewer/glue_qqp_same_thing/). Les colonnes qui vous nous intéressez sont \"inputs_pretokenized\" et \"targets_pretokenized\":\n",
    "- \"inputs_pretokenized\":'Are the questions \"How is the life of a math student? Could you describe your own experiences?\" and \"Which level of prepration is enough for the exam jlpt5?\" asking the same thing? '\n",
    "=> Il s'agit pour chaque observation d'une paire de phrases jointes par \"and\" \n",
    "=> Remarque: il s'agit de questions pour l'ensemble des observations\n",
    "- \"targets_pretokenized\": est-ce que la paire de phrases précédente est une paraphrase ou non? \"yes\" => Il s'agit bien d'une paraphrase et \"no\" les phrases ne sont pas des paraphrases\n",
    "\n",
    "\n",
    "A la fin, on a:\n",
    "\n",
    "- \"inputs\": [\"How is the life of a math student? Could you describe your own experiences?\",\"Which level of prepration is enough for the exam jlpt5?\"] obtenu en utilisant une regex adapté au contexte\n",
    "- \"labels\": On a encodé les labels en {0,1}: 0 => pas de paraphrase , 1 => paraphrase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset p3 (/Users/luciegabagnou/.cache/huggingface/datasets/bigscience___p3/glue_qqp_same_thing/0.1.0/204f22caf7f0cbaf01a8631ec396c1cab69f8d71f276fb8619fae696536874ab)\n",
      "100%|██████████| 3/3 [00:00<00:00, 139.20it/s]\n"
     ]
    }
   ],
   "source": [
    "huggingface_extractor = HuggingFaceExtracting(\"bigscience/P3\",\"glue_qqp_same_thing\")\n",
    "huggingface_extractor.load_huggingface_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = huggingface_extractor.extract(\"train\")\n",
    "test = huggingface_extractor.extract(\"test\")\n",
    "validation = huggingface_extractor.extract(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[How is the life of a math student? Could you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[How do I control my horny emotions?, How do y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[What causes stool color to change to yellow?,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[What can one do after MBBS?, What do i do aft...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Where can I find a power outlet for my laptop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  labels\n",
       "0  [How is the life of a math student? Could you ...       0\n",
       "1  [How do I control my horny emotions?, How do y...       1\n",
       "2  [What causes stool color to change to yellow?,...       0\n",
       "3  [What can one do after MBBS?, What do i do aft...       1\n",
       "4  [Where can I find a power outlet for my laptop...       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA \n",
    "Il y a 363846 observations (paires de phrases + targets) dans l'échantillon de train, 390965 dans l'échantillon de test, et 40430 dans l'échantillon de validation. Au total, on compte donc 795241 observations.\n",
    "\n",
    "Dans un premier temps, on a réalisé une analyse exploratoire du jeu de données (dans sa globalité) pour comprendre quel était le type de données auquel nous étions confronté. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train,test,validation],axis=0).reset_index()\n",
    "sentences = data[\"inputs\"].values.tolist()\n",
    "sentences=flatten(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de mots median dans la phrase 10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenght=pd.Series(sentences).apply(lambda x: len(x.split()))\n",
    "sns.histplot(lenght)\n",
    "print(\"Nombre de mots median dans la phrase\",round(lenght.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.590482e+06\n",
       "mean     1.112469e+01\n",
       "std      5.822297e+00\n",
       "min      0.000000e+00\n",
       "25%      7.000000e+00\n",
       "50%      1.000000e+01\n",
       "75%      1.300000e+01\n",
       "max      2.370000e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthèse de l'analyse exploratoire\n",
    "- Syntaxe : Puisque toutes les observations sont des questions, leur syntaxe devrait être plutôt similaire. Ainsi, la syntaxe n'est pas un facteur qu'il faut inclure dans notre analyse en tant que caractéristique. Cependant, si nous observions une variété de structures, cela pourrait créer de l'hétérogénéité dans les observations. Dans ce cas, nous devrions réaligner toutes les phrases pour qu'elles aient une structure similaire afin de les comparer. Par conséquent, nous pouvons simplifier notre analyse en nous concentrant sur le contenu sémantique des questions plutôt que sur leur structure syntaxique, qui est relativement simple dans ce cas. \n",
    "- Les mots: La longueur des phrases est plutôt homogène et est concentré autour de 10 mots et 75% des phrases ont une longueur inférieure à 13 mots. En ce qui concerne le lexique, nous ne devrons pas nous focaliser dessus pour discriminer les observations les unes des autres (contrairement à la classification de documents qui se concentre sur le vocabulaire). \n",
    "- Langue: Le modèle sera propre à l'anglais vu qu'il s'agit de l'unique langue employé dans les phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Pour cette partie, nous avons créé une classe **ETLPipeline** : une classe représentant un pipeline ETL pour les datasets de texte. Elle comprend des méthodes pour normaliser les entrées, transformer les paires de phrases et les étiquettes en entrées appropriées pour un modèle de classification de texte, et exporter des données.\n",
    "La fonction principale qui traite le processing du texte est:\n",
    "\n",
    "\n",
    "```python\n",
    "def standardize_text_inputs(self, input_data):\n",
    "    self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def process_sentence(sentence):\n",
    "        sentence = contractions.fix(sentence)\n",
    "        sentence = sentence.replace('\"', \"\").replace('?', \"\")\n",
    "        tokens = nltk.word_tokenize(sentence.lower())\n",
    "        if self.lemmatize_option is True:\n",
    "            return [self.lemmatizer.lemmatize(word) for word in tokens if word.isalpha()]\n",
    "        else:\n",
    "            return [word for word in tokens if word.isalpha()]\n",
    "\n",
    "    all_tokens = [process_sentence(sentence) for sentence in input_data]\n",
    "\n",
    "    if self.join_option:\n",
    "        all_tokens = [\" \".join(tokens) for tokens in all_tokens]\n",
    "        \n",
    "    return all_tokens\n",
    "        \n",
    "```\n",
    "Comme on peut le voir, elle effectue différents étapes: \n",
    "- enlève les contractions du type \"I'm\" et les convertit en \"I am\"\n",
    "- remplace les signes de ponctuations parasites tel que \"\"\"\" et \"?\"\n",
    "- met en minuscules les caractères et découpe en tokens les mots (selon nltk)\n",
    "- si souhaité, la fonction lemmatise ce qui peut permettre d'uniformiser les mots en cas de pluriel, conjugaison..\n",
    "- enfin on garde uniquement les élements sont des lettres\n",
    "- selon le word embedding utilisé, on laisse le choix à l'utilisateur de s'il souhaite récupérer la phrase préprocessé sous forme de liste de tokens ou bien d'une phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ETLPipeline()\n",
    "#La \"méthode\" exécute l'ensemble de la pipeline\n",
    "train_data = preprocessor.transform(train)\n",
    "test_data = preprocessor.transform(test)\n",
    "valid_data = preprocessor.transform(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "Dans cette partie, nous avons utilisé la classe **WordEmbedding**: elle est utilisée pour créer une représentation vectorielle pour les mots en utilisant un modèle d'embedding de mots pré-entraîné. La classe possède des méthodes:\n",
    "-  pour fit un tokenizer sur les données d'entraînement (ensemble des phrases)\n",
    "- pour tokenizer et padder (vectoriser et uniformiser la longueur) des séquences d'entrée (sur les phrases 1 puis 2 respectivement)\n",
    "- pour charger le modèle pré-entraîné (qui devront être accessibles dans models). Le modèle est disponible sur Fastext à l'adresse:https://fasttext.cc/docs/en/crawl-vectors.html. \n",
    "Pour accéder à la matrice de poids utilisée ici:\n",
    "``` python\n",
    ">>> import fasttext\n",
    ">>> import fasttext.util\n",
    ">>> ft = fasttext.load_model('cc.en.300.bin')\n",
    ">>> fasttext.util.reduce_model(ft, 100)\n",
    ">>> ft.save_model('cc.en.100.bin')\n",
    "```\n",
    "\n",
    "- pour construire une matrice de poids qui sera utilisée pour initialiser les poids de la couche d'embedding dans un modèle de réseau de neurones: il s'agit d'une couche partagée entre les deux inputs (les deux phrases d'entrée) et les mêmes poids sont utilisés pour vectoriser toutes les phrases (même si c'est sur 2 branches différentes).\n",
    "\n",
    "Ici, nous faisons un zoom sur la construction de la matrice des poids:\n",
    "\n",
    "```` python\n",
    "def build_weight_matrix(self):\n",
    "    vocab_size = len(self.tokenizer.word_index) + 1\n",
    "    weight_matrix = np.zeros((vocab_size, self.embedding_size))\n",
    "    for word, i in self.tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = self.pretrained_model[word]\n",
    "            weight_matrix[i] = embedding_vector\n",
    "        except KeyError:\n",
    "            weight_matrix[i] = np.random.uniform(-5, 5, self.embedding_size)\n",
    "    return weight_matrix\n",
    "````\n",
    "Comme on peut le voir, la fonction construit une matrice de poids à partir d'un modèle d'embedding de mots pré-entraîné et d'un tokenizer. La matrice de poids est utilisée pour initialiser les poids de la couche d'embedding dans un modèle de réseau de neurones.\n",
    "Plus précisément, pour chaque mot dans le vocabulaire, la méthode tente de récupérer son vecteur d'embedding à partir du modèle d'embedding pré-entraîné. Si le mot est présent dans le modèle, la méthode utilise son vecteur d'embedding comme poids pour la ligne correspondante dans la matrice de poids. Si le mot n'est pas présent dans le modèle, la méthode initialise une ligne aléatoire de la matrice de poids avec des valeurs uniformément distribuées entre -5 et 5.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on a utilisé un modèle FastText (explication dans le rapport) car il semblait le plus adapté pour traiter les mots \"hors vocabulaire\" c'est-à-dire les mots non connus lors de la prédiction (si typiquement un mot d'une prédiction n'était pas présent dans l'échantillon d'apprentissage). \n",
    "Nous tenterons plus tard de changer de modèle en utilisant Word2Vec pour voir si cela peut améliorer les performances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on effectue différentes étapes:\n",
    "- On instancie l'objet qui fait le word-embedding en indiquant le type de modèle pré-entraîné et le chemin d'accès du modèle utilisé\n",
    "- On ajuste le tokenizer propre au modèle à partir du corpus de texte d'entraînement (il s'agit d'une vectorisation simple)\n",
    "- On charge le modèle pré-entrainé \n",
    "- On récupère les inputs tokenizés et uniformisés en longueur\n",
    "- On créée une matrice de poids basé sur la fonction vu précédemment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_embedder = WordEmbedding(15,\"FastText\",\"cc.en.100.bin\")\n",
    "word_embedder.tokenizer(train_data[\"sentences_1\"]+ train_data[\"sentences_2\"])\n",
    "word_embedder.load_pretrained_model()\n",
    "train_sentences_1 = word_embedder.tokenize_and_pad(train_data[\"sentences_1\"])\n",
    "train_sentences_2 = word_embedder.tokenize_and_pad(train_data[\"sentences_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = word_embedder.build_weight_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fait la même chose pour l'échantillon de test\n",
    "test_data = preprocessor.transform(test)\n",
    "test_sentences_1 = word_embedder.tokenize_and_pad(test_data[\"sentences_1\"])\n",
    "test_sentences_2 = word_embedder.tokenize_and_pad(test_data[\"sentences_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fait la même chose pour l'échantillon de validation\n",
    "valid_data = preprocessor.transform(validation)\n",
    "valid_sentences_1 = word_embedder.tokenize_and_pad(valid_data[\"sentences_1\"])\n",
    "valid_sentences_2 = word_embedder.tokenize_and_pad(valid_data[\"sentences_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle Siamois LSTM\n",
    "Notre modèle principal et ses résultats sont à retrouver dans cette partie. Comme expliqué dans le rapport, après avoir réalisé le word-embedding:\n",
    "- Les représentations sont passées dans une couche cachée de LSTM pour capturer les relations entre les mots\n",
    "- Les sorties de cette couche sont ensuite concaténées et comparées via une couche de distance pour calculer la similarité entre les deux éléments. \n",
    "\n",
    "A cette occasion, nous avons construit une classe \"SiameseNet\" qui permet de reconstruire facilement le modèle (les paramètres/hyperparamètres utilisés sont mis par défaut).\n",
    "\n",
    "**Remarque**:\n",
    "A partir de cette structure simple, nous avons tenté des améliorations en utilisant notamment des Bi-LSTM ainsi que des GRU mais ici nous présentons uniquement le modèle pertinent. \n",
    "Il est toutefois possible de runner le code en utilisant d'autres types de couches (paramètre \"hidden_layer_architecture\" ainsi que \"bi_directional_architecture_option\" si on souhaite utiliser une couche bidirectionnelle).\n",
    "\n",
    "Après avoir sélectionné ce modèle, nous avons fait un finetuning pour voir si certains paramètres pouvaient permettre d'améliorer l'accuracy (en veillant à ne pas overfitter). Le code est le suivant:\n",
    "- On crée le modèle et les range-values pour les paramètres/hyperparamètres à tester:\n",
    "```python \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "import keras.backend as K\n",
    "from scripts.model import manhattan_distance,contrastive_loss\n",
    "\n",
    "def build_model(hp):\n",
    "    input_dim = 15\n",
    "    input_dim_embedding = weight_matrix.shape[0]\n",
    "    output_dim_embedding = weight_matrix.shape[1]\n",
    "    distance_layer_function = manhattan_distance\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)\n",
    "\n",
    "    ### DEFINITION DES VALEURS A TESTER\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'sgd'])\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "    lstm_neurons = hp.Int('lstm_layers', min_value=64, max_value=256, step=32)\n",
    "\n",
    "\n",
    "    #MODELE\n",
    "    input1 = tf.keras.layers.Input(shape=(input_dim,))\n",
    "    input2 = tf.keras.layers.Input(shape=(input_dim,))\n",
    "    shared_embedding = tf.keras.layers.Embedding(input_dim=input_dim_embedding, output_dim=output_dim_embedding, weights=[weight_matrix])\n",
    "    shared_lstm = tf.keras.layers.LSTM(lstm_neurons)\n",
    "    encoded1 = shared_lstm(shared_embedding(input1))\n",
    "    encoded1 = tf.keras.layers.Dropout(rate=dropout_rate)(encoded1)\n",
    "    encoded2 = shared_lstm(shared_embedding(input2))\n",
    "    encoded2 = tf.keras.layers.Dropout(rate=dropout_rate)(encoded2)\n",
    "    merged_vector = tf.keras.layers.Lambda(lambda x: distance_layer_function(x[0], x[1]))([encoded1, encoded2])\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(merged_vector)\n",
    "    siamese_net = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "    siamese_net.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "    return siamese_net\n",
    "\n",
    "```\n",
    "- On définit le tuner:\n",
    "\n",
    "```python\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=2,\n",
    "    directory='my_dir',\n",
    "    project_name='my_project')\n",
    "# Early stopping si la validation accuracy ne s'améliore pas\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "````\n",
    "\n",
    "- On lance le tuner:\n",
    "```python\n",
    "#grid\n",
    "tuner.search(\n",
    "    [train_sentences_1,train_sentences_2],\n",
    "    np.array(train_data[\"label\"]),\n",
    "    epochs=5,\n",
    "    validation_data=([valid_sentences_1,valid_sentences_2], np.array(valid_data[\"label\"])),\n",
    "    callbacks=[stop_early]\n",
    ")\n",
    "```\n",
    "On récupère les meilleurs estimateurs:\n",
    "```python\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=10)[0]\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir/my_project/oracle.json\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "224               |?                 |lstm_layers\n",
      "0.4               |?                 |dropout_rate\n",
      "adam              |?                 |optimizer\n",
      "1e-05             |?                 |learning_rate\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 22:46:47.538467: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-27 22:46:47.974768: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-27 22:46:47.982061: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-27 22:46:48.329908: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-27 22:46:48.361224: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11371/11371 [==============================] - ETA: 0s - loss: 0.6421 - accuracy: 0.6282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 23:00:59.429114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-27 23:00:59.615358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-27 23:00:59.619035: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11371/11371 [==============================] - 868s 76ms/step - loss: 0.6421 - accuracy: 0.6282 - val_loss: 0.6077 - val_accuracy: 0.6302\n",
      "Epoch 2/5\n",
      "11371/11371 [==============================] - 588s 52ms/step - loss: 0.5980 - accuracy: 0.6339 - val_loss: 0.5890 - val_accuracy: 0.6374\n",
      "Epoch 3/5\n",
      " 5295/11371 [============>.................] - ETA: 6:51 - loss: 0.5826 - accuracy: 0.6430"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Value             |Best Value So Far |Hyperparameter\n",
    "192               |256               |lstm_layers\n",
    "0.001             |0.001             |learning_rate\n",
    "0.1               |0                 |dropout_rate\n",
    "rmsprop           |adam              |optimizer\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "import keras.backend as K\n",
    "from scripts.model import manhattan_distance,contrastive_loss\n",
    "\n",
    "def build_model(hp):\n",
    "    input_dim = 15\n",
    "    input_dim_embedding = weight_matrix.shape[0]\n",
    "    output_dim_embedding = weight_matrix.shape[1]\n",
    "    distance_layer_function = manhattan_distance\n",
    "\n",
    "    input1 = tf.keras.layers.Input(shape=(input_dim,))\n",
    "    input2 = tf.keras.layers.Input(shape=(input_dim,))\n",
    "\n",
    "    shared_embedding = tf.keras.layers.Embedding(input_dim=input_dim_embedding, output_dim=output_dim_embedding, weights=[weight_matrix])\n",
    "    shared_lstm = tf.keras.layers.LSTM(hp.Int('lstm_layers', min_value=64, max_value=256, step=32))\n",
    "    encoded1 = shared_lstm(shared_embedding(input1))\n",
    "    encoded1 = tf.keras.layers.Dropout(rate=hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1))(encoded1)\n",
    "    encoded2 = shared_lstm(shared_embedding(input2))\n",
    "    encoded2 = tf.keras.layers.Dropout(rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1),)(encoded2)\n",
    "    merged_vector = tf.keras.layers.Lambda(lambda x: distance_layer_function(x[0], x[1]))([encoded1, encoded2])\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(merged_vector)\n",
    "    \n",
    "    siamese_net = tf.keras.models.Model(inputs=[input1, input2], outputs=output)\n",
    "        # Choix de l'optimiseur et du learning rate\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    siamese_net.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return siamese_net\n",
    "\n",
    "\n",
    "# Create a tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=2,\n",
    "    directory='my_dir',\n",
    "    project_name='my_project')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(\n",
    "    [train_sentences_1,train_sentences_2],\n",
    "    np.array(train_data[\"label\"]),\n",
    "    epochs=5,\n",
    "    validation_data=([valid_sentences_1,valid_sentences_2], np.array(valid_data[\"label\"])),\n",
    "    callbacks=[stop_early]\n",
    ")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=10)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_learning_rate = best_hps.get('learning_rate')\n",
    "best_hidden_layer_lstm = best_hps.get('lstm_layers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"lambda_1\" (type Lambda).\n\n'str' object is not callable\n\nCall arguments received by layer \"lambda_1\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)']\n  • mask=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmanhattan_distance\u001b[39m(A, B):\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39msum(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mabs(A \u001b[39m-\u001b[39m B), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m siamese_lstm_model\u001b[39m=\u001b[39m SiameseNet(max_len\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,activation_function_output\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msigmoid\u001b[39;49m\u001b[39m\"\u001b[39;49m,distance_layer_function\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbinary_crossentropy\u001b[39;49m\u001b[39m\"\u001b[39;49m,hidden_layer_architecture\u001b[39m=\u001b[39;49m LSTM,hidden_layer_neurons\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,weight_matrix\u001b[39m=\u001b[39;49mweight_matrix)\n\u001b[1;32m      7\u001b[0m siamese_lstm_model_history \u001b[39m=\u001b[39m  siamese_lstm_model\u001b[39m.\u001b[39mfit(train_sentences_1,train_sentences_2,np\u001b[39m.\u001b[39marray(train_data[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]),test_sentences_1,test_sentences_2,np\u001b[39m.\u001b[39marray(test_data[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]),cost_function\u001b[39m=\u001b[39mcontrastive_loss,optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m), batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MOSEF/ML_AVANCE/PROJET/paraphrase-identification/scripts/model.py:71\u001b[0m, in \u001b[0;36mSiameseNet.__init__\u001b[0;34m(self, max_len, weight_matrix, bi_directional_architecture_option, hidden_layer_architecture, hidden_layer_neurons, distance_layer_function, activation_function_output)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistance_layer_function \u001b[39m=\u001b[39m distance_layer_function\n\u001b[1;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_function_output \u001b[39m=\u001b[39m activation_function_output\n\u001b[0;32m---> 71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_model()\n",
      "File \u001b[0;32m~/Documents/MOSEF/ML_AVANCE/PROJET/paraphrase-identification/scripts/model.py:97\u001b[0m, in \u001b[0;36mSiameseNet.build_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m encoded2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mBatchNormalization()(encoded2)        \n\u001b[1;32m     96\u001b[0m \u001b[39m#Concatenate distance between 1 and 2\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m merged_vector \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mLambda(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistance_layer_function(x[\u001b[39m0\u001b[39;49m], x[\u001b[39m1\u001b[39;49m]))([encoded1, encoded2])\n\u001b[1;32m     98\u001b[0m \u001b[39m#Batch Normalization\u001b[39;00m\n\u001b[1;32m     99\u001b[0m output \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mBatchNormalization()(merged_vector)\n",
      "File \u001b[0;32m~/miniconda/envs/dl_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/MOSEF/ML_AVANCE/PROJET/paraphrase-identification/scripts/model.py:97\u001b[0m, in \u001b[0;36mSiameseNet.build_model.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     95\u001b[0m encoded2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mBatchNormalization()(encoded2)        \n\u001b[1;32m     96\u001b[0m \u001b[39m#Concatenate distance between 1 and 2\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m merged_vector \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLambda(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistance_layer_function(x[\u001b[39m0\u001b[39;49m], x[\u001b[39m1\u001b[39;49m]))([encoded1, encoded2])\n\u001b[1;32m     98\u001b[0m \u001b[39m#Batch Normalization\u001b[39;00m\n\u001b[1;32m     99\u001b[0m output \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mBatchNormalization()(merged_vector)\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"lambda_1\" (type Lambda).\n\n'str' object is not callable\n\nCall arguments received by layer \"lambda_1\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 128), dtype=float32)', 'tf.Tensor(shape=(None, 128), dtype=float32)']\n  • mask=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM\n",
    "\n",
    "siamese_lstm_model= SiameseNet(max_len=15,activation_function_output=\"sigmoid\",distance_layer_function=\"binary_crossentropy\",hidden_layer_architecture= LSTM,hidden_layer_neurons=128,weight_matrix=weight_matrix)\n",
    "siamese_lstm_model_history =  siamese_lstm_model.fit(train_sentences_1,train_sentences_2,np.array(train_data[\"label\"]),test_sentences_1,test_sentences_2,np.array(test_data[\"label\"]),cost_function=contrastive_loss,optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: Transfer Learning avec BERT\n",
    "\n",
    "Juste pour comparer, nous avons également fine-tuné BERT pour voir les performances en utilisant des Transformers:\n",
    "\n",
    "Nous avons créé une classe dédiée nommée \"BertTransferModel\", s'éxecutant comme ceci:\n",
    "```python\n",
    "bert_model = BertTransferModel()\n",
    "bert_model.fit(train_data[\"sentences_1\"], train_data[\"sentences_2\"], train_data[\"labels\"])\n",
    "test_sentences_1 = [\"This is a test.\", \"How are you?\"]\n",
    "test_sentences_2 = [\"It is only a test.\", \"I'm fine, thank you.\"]\n",
    "preds = bert_model.predict(test_sentences_1, test_sentences_2)\n",
    "print(preds)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "bert_model = torch.load('saved_model.pt')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('dl_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58139a97a23f8524c35064e91912c687e768b6a827197604e5a6b0cb6960b4eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
